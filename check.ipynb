{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/.pyenv/versions/3.10.11/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from difflib import SequenceMatcher\n",
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('postcode.csv', sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test_postal.csv', sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \"postal\" contains special characters in the following rows:\n",
      "      postal\n",
      "24   789872#\n",
      "141  638377#\n",
      "268  259621#\n",
      "306  437560#\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('[^a-zA-Z0-9]+')\n",
    "for col in df2.columns:\n",
    "    # Convert the column to a string before using the str accessor might need to change back to int depend on db\n",
    "    matches = df2[col].astype(str).str.contains(regex)\n",
    "    if matches.any():\n",
    "        rows = df2.loc[matches]\n",
    "        print(f'Column \"{col}\" contains special characters in the following rows:')\n",
    "        print(rows)\n",
    "\n",
    "        # hmmmm cannot replace...\n",
    "        # rows.replace(regex, \"\")\n",
    "        # print(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 25 @ Col postal: 789872#\n",
      "Row 142 @ Col postal: 638377#\n",
      "Row 269 @ Col postal: 259621#\n",
      "Row 307 @ Col postal: 437560#\n"
     ]
    }
   ],
   "source": [
    "max_lengths = {'postal': 6}\n",
    "\n",
    "for i, row in df2.iterrows():\n",
    "    for col, max_length in max_lengths.items():\n",
    "        if len(str(row[col])) > max_length:\n",
    "            print(f\"Row {i+1} @ Col {col}: {row[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('postcodetest.csv', sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       postal  latitude_x  longtitude_x  \\\n",
      "0      398614    1.312763    103.883519   \n",
      "1      398721    1.312390    103.881504   \n",
      "2      629875    1.309135    103.679463   \n",
      "3      439731    1.305466    103.895674   \n",
      "4      659592    1.344619    103.749789   \n",
      "...       ...         ...           ...   \n",
      "25261  210662    1.306246    103.849956   \n",
      "25262  210663    1.305681    103.850858   \n",
      "25263  210664    1.306133    103.851113   \n",
      "25264  579792    1.347091    103.854878   \n",
      "25265  168895    1.285903    103.834011   \n",
      "\n",
      "                                    searchval_x blk_no_x  \\\n",
      "0                                      # 1 LOFT        1   \n",
      "1                                    # 1 SUITES        1   \n",
      "2                 1 BENOI ROAD SINGAPORE 629875        1   \n",
      "3              1 BOSCOMBE ROAD SINGAPORE 439731        1   \n",
      "4      1 BUKIT BATOK STREET 22 SINGAPORE 659592        1   \n",
      "...                                         ...      ...   \n",
      "25261             ZHUJIAO CENTRE (TEKKA MARKET)      662   \n",
      "25262             ZHUJIAO CENTRE (TEKKA MARKET)      663   \n",
      "25263             ZHUJIAO CENTRE (TEKKA MARKET)      664   \n",
      "25264     ZION BISHAN BIBLE PRESBYTERIAN CHURCH        4   \n",
      "25265                        ZION SPORTS CORNER       10   \n",
      "\n",
      "                 road_name_x                             building_x  \\\n",
      "0          LORONG 24 GEYLANG                               # 1 LOFT   \n",
      "1          LORONG 20 GEYLANG                             # 1 SUITES   \n",
      "2                 BENOI ROAD                                    NIL   \n",
      "3              BOSCOMBE ROAD                                    NIL   \n",
      "4      BUKIT BATOK STREET 22                                    NIL   \n",
      "...                      ...                                    ...   \n",
      "25261           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25262           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25263           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25264       BISHAN STREET 13  ZION BISHAN BIBLE PRESBYTERIAN CHURCH   \n",
      "25265          SENG POH ROAD                     ZION SPORTS CORNER   \n",
      "\n",
      "                                               address_x  postal.1_x  \\\n",
      "0          1 LORONG 24 GEYLANG # 1 LOFT SINGAPORE 398614      398614   \n",
      "1        1 LORONG 20 GEYLANG # 1 SUITES SINGAPORE 398721      398721   \n",
      "2                          1 BENOI ROAD SINGAPORE 629875      629875   \n",
      "3                       1 BOSCOMBE ROAD SINGAPORE 439731      439731   \n",
      "4               1 BUKIT BATOK STREET 22 SINGAPORE 659592      659592   \n",
      "...                                                  ...         ...   \n",
      "25261  662 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210662   \n",
      "25262  663 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210663   \n",
      "25263  664 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210664   \n",
      "25264  4 BISHAN STREET 13 ZION BISHAN BIBLE PRESBYTER...      579792   \n",
      "25265  10 SENG POH ROAD ZION SPORTS CORNER SINGAPORE ...      168895   \n",
      "\n",
      "       latitude_y  longtitude_y                               searchval_y  \\\n",
      "0        1.312763    103.883519                                  # 1 LOFT   \n",
      "1        1.312390    103.881504                                # 1 SUITES   \n",
      "2        1.309135    103.679463             1 BENOI ROAD SINGAPORE 629875   \n",
      "3        1.305466    103.895674          1 BOSCOMBE ROAD SINGAPORE 439731   \n",
      "4        1.344619    103.749789  1 BUKIT BATOK STREET 22 SINGAPORE 659592   \n",
      "...           ...           ...                                       ...   \n",
      "25261    1.306246    103.849956             ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25262    1.305681    103.850858             ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25263    1.306133    103.851113             ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25264    1.347091    103.854878     ZION BISHAN BIBLE PRESBYTERIAN CHURCH   \n",
      "25265    1.285903    103.834011                        ZION SPORTS CORNER   \n",
      "\n",
      "      blk_no_y            road_name_y                             building_y  \\\n",
      "0            1      LORONG 24 GEYLANG                               # 1 LOFT   \n",
      "1            1      LORONG 20 GEYLANG                             # 1 SUITES   \n",
      "2            1             BENOI ROAD                                    NIL   \n",
      "3            1          BOSCOMBE ROAD                                    NIL   \n",
      "4            1  BUKIT BATOK STREET 22                                    NIL   \n",
      "...        ...                    ...                                    ...   \n",
      "25261      662           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25262      663           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25263      664           BUFFALO ROAD          ZHUJIAO CENTRE (TEKKA MARKET)   \n",
      "25264        4       BISHAN STREET 13  ZION BISHAN BIBLE PRESBYTERIAN CHURCH   \n",
      "25265       10          SENG POH ROAD                     ZION SPORTS CORNER   \n",
      "\n",
      "                                               address_y  postal.1_y  \n",
      "0          1 LORONG 24 GEYLANG # 1 LOFT SINGAPORE 398614      398614  \n",
      "1        1 LORONG 20 GEYLANG # 1 SUITES SINGAPORE 398721      398721  \n",
      "2                          1 BENOI ROAD SINGAPORE 629875      629875  \n",
      "3                       1 BOSCOMBE ROAD SINGAPORE 439731      439731  \n",
      "4               1 BUKIT BATOK STREET 22 SINGAPORE 659592      659592  \n",
      "...                                                  ...         ...  \n",
      "25261  662 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210662  \n",
      "25262  663 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210663  \n",
      "25263  664 BUFFALO ROAD ZHUJIAO CENTRE (TEKKA MARKET)...      210664  \n",
      "25264  4 BISHAN STREET 13 ZION BISHAN BIBLE PRESBYTER...      579792  \n",
      "25265  10 SENG POH ROAD ZION SPORTS CORNER SINGAPORE ...      168895  \n",
      "\n",
      "[25266 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df1, df3, on='postal', how='inner')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = merged_df.drop(columns=['', ''])\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to merge while delete the col, not working yet\n",
    "\n",
    "# merged_df = pd.merge(df1[['blk_no', 'road_name']], df2, on='postal', how='inner')\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230428\n"
     ]
    }
   ],
   "source": [
    "today_date = dt.date.today().strftime(\"%Y%m%d\")\n",
    "print(today_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df1.iloc[4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SequenceMatcher(None, 'asdasd', 'dsadsa').ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'col1': ['apple', 'banana', 'carrot', 'dog', 'elephant'], 'col2': ['apple', 'bandana123', 'care123', '123cat', 'eagl232e']})\n",
    "\n",
    "# threshold = 70\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     fratio = fuzz.ratio(row['col1'], row['col2'])\n",
    "#     if fratio >= threshold:\n",
    "#         print(f\"Columns 'col1' and 'col2' in row {i+1} have a similarity of {fratio:.2f}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.4\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     ratio = SequenceMatcher(None, row['col1'], row['col2']).ratio()\n",
    "#     if ratio >= threshold:\n",
    "#         print(f\"Columns 'col1' and 'col2' in row {i+1} have a similarity of {ratio*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'carrot', 'cat dog cat', 'elephant','testing', 'testing1234567789', 'testing testing'],\n",
    "                   'col2': ['apple', 'bandana123', 'care123', 'cat dog dog', 'eagl232e', 'testloling', 'testing', 'test testing test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_similar_rows_ver1(df, col1, col2, threshold):\n",
    "#     similar_rows = []\n",
    "#     for i, row in df.iterrows():\n",
    "#         ratio = SequenceMatcher(None, row[col1], row[col2]).ratio()\n",
    "#         if ratio >= threshold:\n",
    "#             similar_rows.append(i)\n",
    "#     return similar_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_rows_ver2(df, col1, col2, threshold):\n",
    "    for i, row in df.iterrows():\n",
    "        ratio = SequenceMatcher(None, row[col1], row[col2]).ratio()\n",
    "        if ratio == 1.0:\n",
    "            df.loc[i, col2] = row[col2].replace(row[col1], \"\")\n",
    "            print(f\"Row {i+1}: {col2} is deleted due to {row[col1]} in {col2}.\")\n",
    "        elif ratio >= threshold:\n",
    "            print(f\"Row {i+1}: have a similarity of {ratio*100:.2f}% on {col1} & {col2}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_rows_ver3(df, col1, col2, threshold):\n",
    "    for i, row in df.iterrows():\n",
    "        ratio = SequenceMatcher(None, row[col1], row[col2]).ratio()\n",
    "        if ratio == 1.0:\n",
    "            col1dup = row[col1]\n",
    "            col2dup = row[col2]\n",
    "            df.loc[i, col2] = col2dup.replace(col1dup, \"\")\n",
    "            print(f\"Row {i+1}: {col2} is deleted due to {col1dup} in {col2}.\")\n",
    "        elif ratio >= threshold:\n",
    "            print(f\"Row {i+1}: have a similarity of {ratio*100:.2f}% on {col1} & {col2}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: col2 is deleted due to apple in col2.\n",
      "Row 2: have a similarity of 75.00% on col1 & col2.\n",
      "Row 4: have a similarity of 72.73% on col1 & col2.\n",
      "Row 6: have a similarity of 82.35% on col1 & col2.\n",
      "Row 8: have a similarity of 75.00% on col1 & col2.\n",
      "                col1               col2\n",
      "0              apple                   \n",
      "1             banana         bandana123\n",
      "2             carrot            care123\n",
      "3        cat dog cat        cat dog dog\n",
      "4           elephant           eagl232e\n",
      "5            testing         testloling\n",
      "6  testing1234567789            testing\n",
      "7    testing testing  test testing test\n"
     ]
    }
   ],
   "source": [
    "get_similar_rows_ver3(df, \"col1\", \"col2\", 0.7)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_similarity(df, col1, col2):\n",
    "    for i, row in df.iterrows():\n",
    "        seq = difflib.SequenceMatcher(None, row[col1].split(), row[col2].split())\n",
    "        ratio = seq.ratio()\n",
    "        if ratio >= 0.1:\n",
    "            print(f\"Row {i+1}: {col1} and {col2} have a word similarity of {ratio*100:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4: col1 and col2 have a word similarity of 66.67%.\n",
      "Row 8: col1 and col2 have a word similarity of 40.00%.\n"
     ]
    }
   ],
   "source": [
    "get_word_similarity(df, 'col1', 'col2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'col1': ['apple', 'banana', 'carrot', 'cat dog cat', 'elephant','testing', 'testing1234567789', 'testing testing'],\n",
    "                   'col2': ['apple', 'bandana123', 'care123', 'cat dog dog', 'eagl232e', 'testloling', 'testing', 'test testing test']})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similarity_ml(data, col1, col2):\n",
    "    vectorizer = TfidfVectorizer(preprocessor=preprocess_text)\n",
    "    X = vectorizer.fit_transform(data[col1])\n",
    "    Y = vectorizer.transform(data[col2])\n",
    "    sim = cosine_similarity(X, Y)\n",
    "\n",
    "    for i in range(sim.shape[0]):\n",
    "        print(f\"Row {i+1}: have a similarity of {sim[i][0]*100:.2f}% on '{data[col1][i]}' & '{data[col2][i]}'.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: have a similarity of 100.00% on 'apple' & 'apple'.\n",
      "Row 2: have a similarity of 0.00% on 'banana' & 'bandana123'.\n",
      "Row 3: have a similarity of 0.00% on 'carrot' & 'care123'.\n",
      "Row 4: have a similarity of 0.00% on 'cat dog cat' & 'cat dog dog'.\n",
      "Row 5: have a similarity of 0.00% on 'elephant' & 'eagl232e'.\n",
      "Row 6: have a similarity of 0.00% on 'testing' & 'testloling'.\n",
      "Row 7: have a similarity of 0.00% on 'testing1234567789' & 'testing'.\n",
      "Row 8: have a similarity of 0.00% on 'testing testing' & 'test testing test'.\n"
     ]
    }
   ],
   "source": [
    "get_similarity_ml(data, 'col1', 'col2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Andy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/Andy/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: have a similarity of 100.00% on 'apple' & 'apple'.\n",
      "Row 2: have no similarity on 'banana' & 'bandana123'.\n",
      "Row 3: have no similarity on 'carrot' & 'care123'.\n",
      "Row 4: have a similarity of 100.00% on 'cat dog cat' & 'cat dog dog'.\n",
      "Row 5: have no similarity on 'elephant' & 'eagl232e'.\n",
      "Row 6: have no similarity on 'testing' & 'testloling'.\n",
      "Row 7: have no similarity on 'testing1234567789' & 'testing'.\n",
      "Row 8: have a similarity of 50.00% on 'testing testing' & 'test testing test'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stop words and punctuation\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "    # join back to string\n",
    "    processed_text = ' '.join(filtered_tokens)\n",
    "    return processed_text\n",
    "\n",
    "def get_similarity(col1, col2):\n",
    "    # preprocess the strings\n",
    "    col1_processed = preprocess(col1)\n",
    "    col2_processed = preprocess(col2)\n",
    "    # get the set of unique words in each column\n",
    "    col1_words = set(col1_processed.split())\n",
    "    col2_words = set(col2_processed.split())\n",
    "    # calculate Jaccard similarity\n",
    "    similarity = len(col1_words.intersection(col2_words)) / len(col1_words.union(col2_words))\n",
    "    return similarity\n",
    "\n",
    "data = pd.DataFrame({'col1': ['apple', 'banana', 'carrot', 'cat dog cat', 'elephant','testing', 'testing1234567789', 'testing testing'],\n",
    "                   'col2': ['apple', 'bandana123', 'care123', 'cat dog dog', 'eagl232e', 'testloling', 'testing', 'test testing test']})\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    similarity = get_similarity(row['col1'], row['col2'])\n",
    "    if similarity > 0:\n",
    "        print(f\"Row {i+1}: have a similarity of {similarity*100:.2f}% on '{row['col1']}' & '{row['col2']}'.\")\n",
    "    else:\n",
    "        print(f\"Row {i+1}: have no similarity on '{row['col1']}' & '{row['col2']}'.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(string.punctuation)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Return the filtered tokens as a string\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def get_similarity_ml(data, col1, col2):\n",
    "    vectorizer = CountVectorizer(preprocessor=preprocess_text)\n",
    "    X = vectorizer.fit_transform(data[col1])\n",
    "    Y = vectorizer.transform(data[col2])\n",
    "\n",
    "    # Convert the sparse matrices to dense matrices\n",
    "    X_dense = X.toarray()\n",
    "    Y_dense = Y.toarray()\n",
    "\n",
    "    sim = 1 - pairwise_distances(X_dense, Y_dense, metric='jaccard')\n",
    "\n",
    "    for i in range(sim.shape[0]):\n",
    "        print(f\"Row {i+1}: have a similarity of {sim[i][0]*100:.2f}% on '{data[col1][i]}' & '{data[col2][i]}'.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: have a similarity of 100.00% on 'apple' & 'apple'.\n",
      "Row 2: have a similarity of 0.00% on 'banana' & 'bandana123'.\n",
      "Row 3: have a similarity of 0.00% on 'carrot' & 'care123'.\n",
      "Row 4: have a similarity of 0.00% on 'cat dog cat' & 'cat dog dog'.\n",
      "Row 5: have a similarity of 0.00% on 'elephant' & 'eagl232e'.\n",
      "Row 6: have a similarity of 0.00% on 'testing' & 'testloling'.\n",
      "Row 7: have a similarity of 0.00% on 'testing1234567789' & 'testing'.\n",
      "Row 8: have a similarity of 0.00% on 'testing testing' & 'test testing test'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andy/Desktop/checking/venv/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "get_similarity_ml(data, 'col1', 'col2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
